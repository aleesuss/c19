{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KLpcQUY2hen"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras import metrics\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from skimage import io\n",
        "#attention\n",
        "from keras.layers import GlobalAveragePooling2D, multiply, LocallyConnected2D, Lambda\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "seed = 232\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNL-p5VPylRO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMaRMQeiz4wT"
      },
      "outputs": [],
      "source": [
        "#import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_aI8-t_0GW4"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pljTOwhu299l"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9YSNK0s3CAg"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "import shutil\n",
        "#import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyeDcaR_ENA1"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading"
      ],
      "metadata": {
        "id": "fEWAaYGVOdTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdBPeOpv8fr3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTKi51UD3LpH"
      },
      "outputs": [],
      "source": [
        "Dataset = \"data_byclass_jan20\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xowY8ZqY3IzH"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"/content/drive/My Drive/\"+Dataset+\".zip\",\"r\") as z:\n",
        "    z.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6cN40z33kT9"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir(\"./boneage-training-dataset\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjnazjEt3vrf"
      },
      "outputs": [],
      "source": [
        "counts = 0\n",
        "for folders, subfolders, filenames in os.walk(\"/content/drive/My Drive/CT/test/covid/\"):\n",
        "    for filename in filenames:\n",
        "        counts=counts+1\n",
        "print(counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhl0gtj34UwK"
      },
      "outputs": [],
      "source": [
        "source_folder = './Gandhi_test6'\n",
        "destination_folder = '/content/drive/My Drive/CT/test/covid/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSoy-V414cpq"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for folders, subfolders, filenames in os.walk(source_folder):\n",
        "    for filename in filenames:\n",
        "      #if filename in file_list:\n",
        "      shutil.move(os.path.join(folders, filename), destination_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAjuawRH287i"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/My Drive/data_byclass_nov12/'\n",
        "\n",
        "fig, ax = plt.subplots(3, 3, figsize=(15, 7))\n",
        "ax = ax.ravel()\n",
        "plt.tight_layout()\n",
        "\n",
        "for i, _set in enumerate(['train', 'val', 'test']):\n",
        "    set_path = input_path+_set\n",
        "    ax[i].imshow(plt.imread(set_path+'/normal/'+os.listdir(set_path+'/normal')[0]), cmap='gray')\n",
        "    ax[i].set_title('Set: {}, Condition: Normal'.format(_set))\n",
        "    ax[i+3].imshow(plt.imread(set_path+'/pneumonia/'+os.listdir(set_path+'/pneumonia')[0]), cmap='gray')\n",
        "    ax[i+3].set_title('Set: {}, Condition: Pneumonia'.format(_set))\n",
        "    ax[i+6].imshow(plt.imread(set_path+'/covid/'+os.listdir(set_path+'/covid')[0]), cmap='gray')\n",
        "    ax[i+6].set_title('Set: {}, Condition: Covid'.format(_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lnzhCy73FIk"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/My Drive/CT/'\n",
        "\n",
        "for _set in ['test']:\n",
        "    n_normal = len(os.listdir(input_path + _set + '/normal'))\n",
        "    n_infect = len(os.listdir(input_path + _set + '/pneumonia'))\n",
        "    n_covid = len(os.listdir(input_path + _set + '/covid'))\n",
        "    print('Set: {}, normal images: {}, pneumonia images: {}, covid images: {}'.format(_set, n_normal, n_infect, n_covid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjCuCsQPYXN9"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/My Drive/CT/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC5-ZoODQZxt"
      },
      "outputs": [],
      "source": [
        "import imghdr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing Data"
      ],
      "metadata": {
        "id": "IkVKp-S1OhLb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0mHxVrX3Odn"
      },
      "outputs": [],
      "source": [
        "def process_data(img_dims, batch_size):\n",
        "    # Data generation objects\n",
        "\n",
        "    #train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \"\"\"\n",
        "    train_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rescale=1./255,\n",
        "    zoom_range=(0.85,1.15),\n",
        "    shear_range = 0.3,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range = 10,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1)\n",
        "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \"\"\"\n",
        "\n",
        "    # This is fed to the network in the specified batch sizes and image dimensions\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "    directory=input_path+'test',\n",
        "    target_size=(img_dims, img_dims),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "    val_gen = val_datagen.flow_from_directory(\n",
        "    directory=input_path+'test',\n",
        "    target_size=(img_dims, img_dims),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "    # I will be making predictions off of the test set in one batch size\n",
        "    # This is useful to be able to get the confusion matrix\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "    \"\"\"\n",
        "    for cond in ['/normal/', '/pneumonia/', '/covid/']:\n",
        "        for img in (os.listdir(input_path + 'test' + cond)):\n",
        "            img = cv2.imread(input_path+'test'+cond+img)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (img_dims, img_dims))\n",
        "            img = np.dstack([img, img, img])\n",
        "            img = img.astype('float32') / 255\n",
        "            if cond=='/normal/':\n",
        "                label = 1\n",
        "            elif cond=='/pneumonia/':\n",
        "                label = 2\n",
        "            elif cond== '/covid/':\n",
        "                label = 0\n",
        "            test_data.append(img)\n",
        "            test_labels.append(label)\n",
        "\n",
        "    test_data = np.array(test_data)\n",
        "    #test_labels = np.array(test_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    #return val_gen\n",
        "    return train_gen, val_gen, test_data, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "OahNwqYIGKqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels =['covid', 'normal', 'pneumonia']"
      ],
      "metadata": {
        "id": "q2pfmaQ597Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#duplicate\n",
        "def process_data(img_dims, batch_size):\n",
        "    # Data generation objects\n",
        "\n",
        "    #train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \"\"\"\n",
        "    train_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rescale=1./255,\n",
        "    zoom_range=(0.85,1.15),\n",
        "    shear_range = 0.3,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range = 10,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1)\n",
        "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \"\"\"\n",
        "\n",
        "    # This is fed to the network in the specified batch sizes and image dimensions\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "    directory=input_path+'test1',\n",
        "    target_size=(img_dims, img_dims),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "    val_gen = val_datagen.flow_from_directory(\n",
        "    directory=input_path+'test1',\n",
        "    target_size=(img_dims, img_dims),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "    \"\"\"\n",
        "    # I will be making predictions off of the test set in one batch size\n",
        "    # This is useful to be able to get the confusion matrix\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "\n",
        "    for cond in ['/normal/', '/pneumonia/', '/covid/']:\n",
        "        for img in (os.listdir(input_path + 'test' + cond)):\n",
        "            img = cv2.imread(input_path+'test'+cond+img)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (img_dims, img_dims))\n",
        "            img = np.dstack([img, img, img])\n",
        "            img = img.astype('float32') / 255\n",
        "            if cond=='/normal/':\n",
        "                label = 1\n",
        "            elif cond=='/pneumonia/':\n",
        "                label = 2\n",
        "            elif cond== '/covid/':\n",
        "                label = 0\n",
        "            test_data.append(img)\n",
        "            test_labels.append(label)\n",
        "\n",
        "    test_data = np.array(test_data)\n",
        "    test_labels = np.array(test_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    #return val_gen\n",
        "    return train_gen, val_gen"
      ],
      "metadata": {
        "id": "LE4zO51-6OdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtWkdKB_3V6K"
      },
      "outputs": [],
      "source": [
        "img_dims = 224\n",
        "epochs = 1\n",
        "batch_size = 8\n",
        "\n",
        "#train_gen, val_gen, test_data, test_labels = process_data(img_dims, batch_size)\n",
        "#train_gen, val_gen = process_data(img_dims, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Models"
      ],
      "metadata": {
        "id": "5kCBINxYOpIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-fvQRE7XdQN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import AUC, CategoricalCrossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9gaPqU33dl4"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape=(img_dims, img_dims, 3))\n",
        "\n",
        "# First conv block\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "#x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Second conv block\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "#x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Third conv block\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "#x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Fourth conv block\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "#x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "# Fifth conv block\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "#x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "# FC layer\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "#x = Dropout(rate=0.7)(x)\n",
        "x = Dense(units=128, activation='relu')(x)\n",
        "#x = Dropout(rate=0.5)(x)\n",
        "x = Dense(units=64, activation='relu')(x)\n",
        "#x = Dropout(rate=0.3)(x)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(units=3, activation='softmax')(x)\n",
        "\n",
        "# Creating model and compiling\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/My Drive/best_weights_cnn1.hdf5', save_best_only=True, save_weights_only=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upG68oKU2XOZ"
      },
      "outputs": [],
      "source": [
        "#from ada\n",
        "inputs = Input(shape=(img_dims, img_dims, 3))\n",
        "\n",
        "# First conv block\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Second conv block\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Third conv block\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "# Fourth conv block\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "# Fifth conv block\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "#Sixth\n",
        "x = SeparableConv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\"\"\"\n",
        "#for experimenting seventh layer\n",
        "#Seventh\n",
        "x = SeparableConv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\"\"\"\n",
        "# FC layer\n",
        "x = Flatten()(x)\n",
        "#x = Dense(units=1024, activation='relu')(x)\n",
        "#x = Dropout(rate=0.7)(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(rate=0.7)(x)\n",
        "x = Dense(units=128, activation='relu')(x)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "x = Dense(units=64, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(units=3, activation='softmax')(x)\n",
        "optimizer = Adam(learning_rate=5e-5,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
        "# Creating model and compiling\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(filepath='./best_weights_ctdump.hdf5', save_best_only=True, save_weights_only=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5q-lKEvq8FuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention mechanism plugged"
      ],
      "metadata": {
        "id": "dan-uqHjOuQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = 16\n",
        "inputs = Input(shape=(img_dims, img_dims, 3))\n",
        "\n",
        "# First conv block\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# attention mechanism\n",
        "\n",
        "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(x)\n",
        "attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
        "attn_layer = LocallyConnected2D(1,\n",
        "                                kernel_size = (1,1),\n",
        "                                padding = 'valid',\n",
        "                                activation = 'sigmoid')(attn_layer)\n",
        "# fan it out to all of the channels\n",
        "up_c2_w = np.ones((1, 1, 1, hidden))\n",
        "up_c2 = Conv2D(hidden, kernel_size = (1,1), padding = 'same',\n",
        "               activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
        "up_c2.trainable = False\n",
        "attn_layer = up_c2(attn_layer)\n",
        "\n",
        "mask_features = multiply([attn_layer, x])\n",
        "gap_features = GlobalAveragePooling2D()(mask_features)\n",
        "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
        "# to account for missing values from the attention model\n",
        "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
        "\n",
        "gap_dr = Dropout(0.5)(gap)\n",
        "dr_steps = Dropout(0.25)(Dense(512, activation = 'relu')(gap_dr))\n",
        "out_layer = Dense(3, activation = 'softmax')(dr_steps) # linear is what 16bit did\n",
        "covid_model = Model(inputs = [inputs], outputs = [out_layer])\n",
        "\n",
        "optimizer =Adam(lr=5e-5,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
        "\n",
        "\n",
        "\n",
        "covid_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(filepath='./best_weights_ctdump.hdf5', save_best_only=True, save_weights_only=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n",
        "\n"
      ],
      "metadata": {
        "id": "tHw6SAVrtxAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covid_model.summary()"
      ],
      "metadata": {
        "id": "IW9py8wNyI29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuja1yuAwrV-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "x = SeparableConv2D(filters=2048, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=2048, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Yg33w1zjPu"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Balancing"
      ],
      "metadata": {
        "id": "zSLfCkw9O1-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVwdX4Y911WA"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "weights = compute_class_weight('balanced', np.unique(train_gen.classes), train_gen.classes)\n",
        "cw = dict(zip( np.unique(train_gen.classes), weights))\n",
        "print(cw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA4uJDTC4BcV"
      },
      "outputs": [],
      "source": [
        "filename='log.csv'\n",
        "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#, steps_per_epoch=val_gen.samples // batch_size,"
      ],
      "metadata": {
        "id": "aXjI0nzH2etp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fixed_generator(generator):\n",
        "    for batch in generator:\n",
        "        yield (batch, batch)"
      ],
      "metadata": {
        "id": "-qwy3XtY4KVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-z1Ivbp3mg1"
      },
      "outputs": [],
      "source": [
        "hist = covid_model.fit(generator=fixed_generator(val_gen),\n",
        "           epochs=1, validation_data=fixed_generator(val_gen), callbacks=[checkpoint,lr_reduce,history_logger])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen.class_indices"
      ],
      "metadata": {
        "id": "07oYmc0rNV4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, lab = next(val_gen)"
      ],
      "metadata": {
        "id": "0xqxrPffNlvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen.samples"
      ],
      "metadata": {
        "id": "gcRkYLjMOTbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_list=[checkpoint,lr_reduce,history_logger]"
      ],
      "metadata": {
        "id": "397f90UEOjWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = covid_model.fit(val_gen,epochs=5, validation_data=val_gen, shuffle=True,  verbose=2)"
      ],
      "metadata": {
        "id": "UiBak9aQN8fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the attention layer since it is the only one with a single output dim\n",
        "for attn_layer in covid_model.layers:\n",
        "    c_shape = attn_layer.get_output_shape_at(0)\n",
        "    if len(c_shape)==4:\n",
        "        if c_shape[-1]==1:\n",
        "            print(attn_layer)\n",
        "            break"
      ],
      "metadata": {
        "id": "obtnlsljkK_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X, test_Y = next(val_gen)"
      ],
      "metadata": {
        "id": "z0mHJ_uxkrTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_steps=val_gen.samples // batch_size,"
      ],
      "metadata": {
        "id": "eDo6fud_ftFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzxOgvC82U5D"
      },
      "outputs": [],
      "source": [
        "param_range = np.arange(1,2,0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FORgMz9Z2od_"
      },
      "outputs": [],
      "source": [
        "param_range.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1TO1cwJ3ur5"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['accuracy', 'loss']):\n",
        "    ax[i].plot(param_range,hist.history[met],color ='green')\n",
        "    ax[i].plot(param_range,hist.history['val_'+ met],color ='red')\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyKRlaDw2zWa"
      },
      "outputs": [],
      "source": [
        "plt.subplots(2, figsize=(7,7))\n",
        "for i, met in enumerate(['accuracy', 'loss']):\n",
        "  plt.plot(param_range, ax[i], label=\"Training score\", color=\"red\")\n",
        "  plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"green\")\n",
        "\n",
        "#plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\n",
        "#plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"gainsboro\")\n",
        "\n",
        "plt.title(\"Validation Curve With Random Forest\")\n",
        "plt.xlabel(\"Number Of Trees\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.tight_layout()\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5LK3wHZIkKO"
      },
      "outputs": [],
      "source": [
        "plt.subplots(1, figsize=(7,7))\n",
        "for i, met in enumerate(['accuracy', 'loss']):\n",
        "  plt.plot(param_range, ax[i], label=\"Training score\", color=\"black\")\n",
        "  plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"dimgrey\")\n",
        "\n",
        "  plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\n",
        "  plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"gainsboro\")\n",
        "\n",
        "  plt.title(\"Validation Curve With Random Forest\")\n",
        "  plt.xlabel(\"Number Of Trees\")\n",
        "  plt.ylabel(\"Accuracy Score\")\n",
        "  plt.tight_layout()\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lialy5-a4hx"
      },
      "outputs": [],
      "source": [
        "model_loaded = Model(inputs=inputs, outputs=output)\n",
        "model_loaded.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFM73F_6afOh"
      },
      "outputs": [],
      "source": [
        "#the best so far. don't change\n",
        "model.load_weights('/content/drive/My Drive/best_weights_ctdump.hdf5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing performance"
      ],
      "metadata": {
        "id": "13jH6w0fPCAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsnZ_tmTe3qp"
      },
      "outputs": [],
      "source": [
        "eval_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "test_generator = eval_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/data_byclass_jan20/test/',\n",
        "    target_size = (img_dims, img_dims),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical', shuffle = False\n",
        ")\n",
        "\"\"\"\n",
        "eval_result = model.evaluate(test_generator)\n",
        "print('loss rate at evaluation data :', eval_result[0])\n",
        "print('accuracy rate at evaluation data :', eval_result[1])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX6hKsxEJ6Pn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7P-Q_jtUxF7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "preds = model_loaded.predict(test_generator)\n",
        "pred = np.argmax(preds, axis = 1)\n",
        "acc = accuracy_score(test_generator.classes, pred)*100\n",
        "cm = confusion_matrix(test_generator.classes, pred)\n",
        "#tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-26YfUzyzE8"
      },
      "outputs": [],
      "source": [
        "preds = covid_model.predict(val_gen)\n",
        "pred = np.argmax(preds, axis = 1)\n",
        "acc = accuracy_score(val_gen.classes, pred)*100\n",
        "cm = confusion_matrix(val_gen.classes, pred)\n",
        "#tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZqOt1GA25T2"
      },
      "outputs": [],
      "source": [
        "#the best so far. don't change. with best_weights_ct2.hdf5\n",
        "preds = model_loaded.predict(test_generator)\n",
        "pred = np.argmax(preds, axis = 1)\n",
        "acc = accuracy_score(test_generator.classes, pred)*100\n",
        "cm = confusion_matrix(test_generator.classes, pred)\n",
        "#tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3oXtBK4hCCT"
      },
      "outputs": [],
      "source": [
        "#30\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "preds = model_loaded.predict(test_generator)\n",
        "pred = np.argmax(preds, axis = 1)\n",
        "acc = accuracy_score(test_generator.classes, pred)*100\n",
        "cm = confusion_matrix(test_generator.classes, pred)\n",
        "#tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhlP18y1phs5"
      },
      "outputs": [],
      "source": [
        "#ctcnn1\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "preds = model_loaded.predict(test_generator)\n",
        "pred = np.argmax(preds, axis = 1)\n",
        "acc = accuracy_score(test_generator.classes, pred)*100\n",
        "cm = confusion_matrix(test_generator.classes, pred)\n",
        "#tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3kb3NXzxzLA"
      },
      "outputs": [],
      "source": [
        "TN, FP, FN, TP, TN1, FP1, FN1, TP1, TN2 = cm.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxIR_HqmDsg7"
      },
      "outputs": [],
      "source": [
        "TP = 4692\n",
        "FN = 1482"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhajJfUfEoI5"
      },
      "outputs": [],
      "source": [
        "FP = 352\n",
        "TN = 19640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEVUkhdbyl21"
      },
      "outputs": [],
      "source": [
        "print(TP/(TP+FN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB9ZyO0GpJwM"
      },
      "outputs": [],
      "source": [
        "print('Classification Report')\n",
        "target_names = ['Covid', 'Normal', 'Pneumonia']\n",
        "print(classification_report(test_generator.classes, pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5t58i4m2vJ7"
      },
      "outputs": [],
      "source": [
        "print('Classification Report')\n",
        "target_names = ['Covid', 'Normal', 'Pneumonia']\n",
        "print(classification_report(test_generator.classes, pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV2ZGC8a6r4x"
      },
      "outputs": [],
      "source": [
        "#the best so far. don't change\n",
        "print('Classification Report')\n",
        "target_names = ['Covid', 'Normal', 'Pneumonia']\n",
        "print(classification_report(test_generator.classes, pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyH_7b_NhImX"
      },
      "outputs": [],
      "source": [
        "#30\n",
        "print('Classification Report')\n",
        "target_names = ['Covid', 'Normal', 'Pneumonia']\n",
        "print(classification_report(test_generator.classes, pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPQrV9tdpqex"
      },
      "outputs": [],
      "source": [
        "#ctcnn1\n",
        "print('Classification Report')\n",
        "target_names = ['Covid', 'Normal', 'Pneumonia']\n",
        "print(classification_report(test_generator.classes, pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLUDdv5f8QhD"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "test_generator_gandhialone = test_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/CT/test/',\n",
        "    target_size = (img_dims, img_dims),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical', shuffle = False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wzK7eZM8gSV"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_generator_gandhialone)\n",
        "pred = np.argmax(preds, axis = 1)\n",
        "acc = accuracy_score(test_generator_gandhialone.classes, pred)*100\n",
        "cm = confusion_matrix(test_generator_gandhialone.classes, pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKO6_ylgkJz_"
      },
      "outputs": [],
      "source": [
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-39WtSH39n7d"
      },
      "outputs": [],
      "source": [
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaYFchpp9vgH"
      },
      "outputs": [],
      "source": [
        "print('Classification Report')\n",
        "target_names = ['Covid', 'Normal', 'Pneumonia']\n",
        "print(classification_report(test_generator_gandhialone.classes, pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed3vdk16WO4Y"
      },
      "outputs": [],
      "source": [
        "ppvs = [cm[i,i]/np.sum(cm[:,i]) if np.sum(cm[:,i]) else 0 for i in range(len(cm))]\n",
        "print('PPV Covid: {0:.3f}, Normal: {1:.3f}, Pneumonia: {2:.3f}'.format(ppvs[0],\n",
        "                                                                             ppvs[1],\n",
        "                                                                             ppvs[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StQfnwH_WWXp"
      },
      "outputs": [],
      "source": [
        "class_acc = [cm[i,i]/np.sum(cm[i,:]) if np.sum(cm[i,:]) else 0 for i in range(len(cm))]\n",
        "print('Sens Covid: {0:.3f}, Normal: {1:.3f}, Pneumonia: {2:.3f}'.format(class_acc[0],\n",
        "                                                                               class_acc[1],\n",
        "                                                                               class_acc[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6QM9b4VVuHh"
      },
      "outputs": [],
      "source": [
        "val_gen.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization starts here"
      ],
      "metadata": {
        "id": "I4g2F8EhONNv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZXKR1mnYvif"
      },
      "outputs": [],
      "source": [
        "pip install visual-logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG-hjapgYm69"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import vlogging\n",
        "\n",
        "logger = logging.getLogger(\"demo\")\n",
        "fh = logging.FileHandler('test.html', mode=\"w\")\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logger.addHandler(fh)\n",
        "\n",
        "image = cv2.imread('/content/drive/My Drive/CT/test/covid/C19_603970_26.png')\n",
        "logger.info(vlogging.VisualRecord('Sample Image', image, {'footnote': 'sample image'}, fmt='png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrH7RGqjrepn"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h44zWHO3XNE0"
      },
      "outputs": [],
      "source": [
        "#import cv2\n",
        "#import numpy as np\n",
        "#import tensorflow as tf\n",
        "\n",
        "IMAGE_PATH = '/content/drive/My Drive/CT/test/covid/C19_603970_26.png'\n",
        "LAYER_NAME = 'separable_conv2d_9'\n",
        "CAT_CLASS_INDEX = 0\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
        "img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "#model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    conv_outputs, predictions = grad_model(np.array([img]))\n",
        "    loss = predictions[:, CAT_CLASS_INDEX]\n",
        "\n",
        "output = conv_outputs[0]\n",
        "grads = tape.gradient(loss, conv_outputs)[0]\n",
        "\n",
        "gate_f = tf.cast(output > 0, 'float32')\n",
        "gate_r = tf.cast(grads > 0, 'float32')\n",
        "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
        "\n",
        "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "\n",
        "cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
        "\n",
        "for i, w in enumerate(weights):\n",
        "    cam += w * output[:, :, i]\n",
        "\n",
        "cam = cv2.resize(cam.numpy(), (224, 224))\n",
        "cam = np.maximum(cam, 0)\n",
        "heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
        "\n",
        "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_BGR2RGB), 0.5, cam, 1, 0)\n",
        "plt.imshow(output_image)\n",
        "plt.show()\n",
        "#cv2.imwrite('/content/drive/My Drive/cam.png', output_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlK7P7zITuWQ"
      },
      "outputs": [],
      "source": [
        "LAYER_NAME = 'separable_conv2d_19'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zriw4AmXJw5K"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpiTQ1CqJ5eF"
      },
      "outputs": [],
      "source": [
        "model = VGG16(weights=\"imagenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzgPwzySE1rH"
      },
      "outputs": [],
      "source": [
        "sunglasses= io.imread(\"https://ae01.alicdn.com/kf/HTB1wnD8bcrrK1RjSspaq6AREXXaR/MK100-Tony-Stark-Doll-Head-Carved-Glasses-Seamless-Flexible-Body-1-6-Action-Figure-Scale-Model.jpg_q50.jpg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXPFgKfgQpVF"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = '/content/drive/My Drive/CT/test/covid/C19_603970_26.png'\n",
        "LAYER_NAME = 'separable_conv2d_9'\n",
        "CAT_CLASS_INDEX = 0\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
        "img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYDZb4AtE-0T"
      },
      "outputs": [],
      "source": [
        "sunglasses = cv2.resize(sunglasses, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "x = image.img_to_array(sunglasses)\n",
        "\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "x = preprocess_input(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt_pVWJ_TQDR"
      },
      "outputs": [],
      "source": [
        "x = np.expand_dims(img, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxMnzevYFGI2"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "\n",
        "preds = model.predict(x)\n",
        "\n",
        "class_output = model.output[:, 837]\n",
        "\n",
        "last_conv_layer = model.get_layer(\"block5_conv3\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECIqiQUHSH9d"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(x)\n",
        "\n",
        "class_output = model.output\n",
        "\n",
        "last_conv_layer = model.get_layer(LAYER_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGyc6qZaMjsD"
      },
      "outputs": [],
      "source": [
        "print(class_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDmJFFmpFMdO"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "\"\"\"\n",
        "with tf.GradientTape() as tape:\n",
        "    #predictions = model.predict(x)\n",
        "    predictions = model(x)\n",
        "    loss = predictions[:, 837]\n",
        "    conv_outputs = last_conv_layer.output\n",
        "    #loss = predictions[:, CAT_CLASS_INDEX]\n",
        "\n",
        "output = conv_outputs[0]\n",
        "grads = tape.gradient(loss, last_conv_layer.output)\n",
        "\"\"\"\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "\n",
        "print(grads.shape)\n",
        "\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "print(pooled_grads.shape)\n",
        "\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "for i in range(512):\n",
        "\n",
        "  conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwyQXbWkUp7J"
      },
      "outputs": [],
      "source": [
        "#img1 = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
        "img1 = cv2.resize(image.load_img(IMAGE_PATH), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrBM1koaEb21"
      },
      "outputs": [],
      "source": [
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "\n",
        "print(conv_layer_output_value.shape)\n",
        "\n",
        "print(heatmap.shape)\n",
        "\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "heatmap /= np.max(heatmap)\n",
        "\n",
        "heatmap = cv2.resize(heatmap, (sunglasses.shape[1], sunglasses.shape[0]))\n",
        "\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "superimposed_img = cv2.addWeighted(sunglasses, 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cv2_imshow(heatmap)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZUVUmCAEc1v"
      },
      "outputs": [],
      "source": [
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "\n",
        "print(conv_layer_output_value.shape)\n",
        "\n",
        "print(heatmap.shape)\n",
        "\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "heatmap /= np.max(heatmap)\n",
        "\n",
        "heatmap = cv2.resize(heatmap, (sunglasses.shape[1], sunglasses.shape[0]))\n",
        "\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "superimposed_img = cv2.addWeighted(sunglasses, 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cv2_imshow(heatmap)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMkbVc5dgihK"
      },
      "outputs": [],
      "source": [
        "\n",
        "predict = model.predict(np.array([img]))\n",
        "#predict = model.predict(test_generator)\n",
        "target_class = np.argmax(predict[0])\n",
        "print(\"Target Class = \", target_class, \"corresponding to:\", predict, \"Obese is [0., 1.]\")\n",
        "\n",
        "#original code\n",
        "#print(\"The real value is\",y_ann_data_encoded[example_index])\n",
        "\n",
        "#code for running standalone\n",
        "print(test_generator.classes[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4AZUCiLlzAY"
      },
      "outputs": [],
      "source": [
        "last_conv = model.get_layer('separable_conv2d_9') #last_conv= model.layers[8]\n",
        "grad_model = tf.keras.models.Model([model.inputs], [last_conv.output, model.output])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    conv_outputs, predictions = grad_model(np.array([img]))\n",
        "    loss = predictions[:, target_class]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pVjmiuXnLaj"
      },
      "outputs": [],
      "source": [
        "output = conv_outputs[0] #activations maps from last conv layer\n",
        "grads = tape.gradient(loss, conv_outputs)[0] #function to obtain gradients from last conv layer\n",
        "\n",
        "print(\"grads shape:\", grads.shape)\n",
        "print(\"Model output (loss for the target class):\", loss.shape)\n",
        "print(\"Output froom lat conv layer\", conv_outputs.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40-YhxTsnWdl"
      },
      "outputs": [],
      "source": [
        "activation_map = output[:,0]\n",
        "plt.plot(activation_map)\n",
        "plt.show()\n",
        "\n",
        "Activation_map_image = [activation_map,activation_map,activation_map,activation_map,activation_map,\n",
        "                        activation_map,activation_map,activation_map,activation_map,activation_map,\n",
        "                        activation_map,activation_map,activation_map,activation_map,activation_map]\n",
        "#plt.imshow(Activation_map_image) # vmin=-1, vmax=1) #cmap='gray\n",
        "#plt.colorbar()\n",
        "\n",
        "#c=a.numpy()\n",
        "#c=a.numpy().reshape(1, -1)\n",
        "\n",
        "activation_map[0:15]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sbBmbR0oSLE"
      },
      "outputs": [],
      "source": [
        "gradient = grads[:,0]\n",
        "\n",
        "plt.plot(gradient)\n",
        "plt.show()\n",
        "\n",
        "gradient_map_image = [gradient,gradient,gradient,gradient,gradient,\n",
        "                        gradient,gradient,gradient,gradient,gradient,\n",
        "                        gradient,gradient,gradient,gradient,gradient]\n",
        "#plt.imshow(gradient_map_image) # vmin=-1, vmax=1) #cmap='gray\n",
        "#plt.colorbar()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L6O6uaWoHzU"
      },
      "outputs": [],
      "source": [
        "# Apply guided backpropagation\n",
        "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
        "\n",
        "guide_grads_example = guided_grads[:,0]\n",
        "plt.plot(guide_grads_example)\n",
        "plt.show()\n",
        "\n",
        "guided_grads_image = [guide_grads_example,guide_grads_example,guide_grads_example, guide_grads_example,guide_grads_example,\n",
        "                        guide_grads_example,guide_grads_example,guide_grads_example, guide_grads_example,guide_grads_example,\n",
        "                        guide_grads_example,guide_grads_example,guide_grads_example, guide_grads_example,guide_grads_example]\n",
        "plt.imshow(guided_grads_image) # vmin=-1, vmax=1) #cmap='gray\n",
        "plt.colorbar()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOZ4uiepdi-R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "layers_name = ['conv2D_1']\n",
        "IMAGE_PATH = '/content/drive/My Drive/CT/test/covid/C19_603970_26.png'\n",
        "\n",
        "# Model to examine\n",
        "#model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=True)\n",
        "\n",
        "# Image to pass as input\n",
        "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
        "img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# Get the outputs of layers we want to inspect\n",
        "outputs = [\n",
        "    layer.output for layer in model.layers\n",
        "    if layer.name in layers_name\n",
        "]\n",
        "\n",
        "# Create a connection between the input and those target outputs\n",
        "activations_model = tf.keras.models.Model(model.inputs, outputs=outputs)\n",
        "activations_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Get their outputs\n",
        "activations_1 = activations_model.predict(np.array([img]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inp89GhCOqr8"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from scipy.special import ndtri\n",
        "\n",
        "def _proportion_confidence_interval(r, n, z):\n",
        "    \"\"\"Compute confidence interval for a proportion.\n",
        "\n",
        "    Follows notation described on pages 46--47 of [1].\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    [1] R. G. Newcombe and D. G. Altman, Proportions and their differences, in Statisics\n",
        "    with Confidence: Confidence intervals and statisctical guidelines, 2nd Ed., D. G. Altman,\n",
        "    D. Machin, T. N. Bryant and M. J. Gardner (Eds.), pp. 45-57, BMJ Books, 2000.\n",
        "    \"\"\"\n",
        "\n",
        "    A = 2*r + z**2\n",
        "    B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
        "    C = 2*(n + z**2)\n",
        "    return ((A-B)/C, (A+B)/C)\n",
        "\n",
        "def sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
        "    \"\"\"Compute confidence intervals for sensitivity and specificity using Wilson's method.\n",
        "\n",
        "    This method does not rely on a normal approximation and results in accurate\n",
        "    confidence intervals even for small sample sizes.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    TP : int\n",
        "        Number of true positives\n",
        "    FP : int\n",
        "        Number of false positives\n",
        "    FN : int\n",
        "        Number of false negatives\n",
        "    TN : int\n",
        "        Number of true negatives\n",
        "    alpha : float, optional\n",
        "        Desired confidence. Defaults to 0.95, which yields a 95% confidence interval.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    sensitivity_point_estimate : float\n",
        "        Numerical estimate of the test sensitivity\n",
        "    specificity_point_estimate : float\n",
        "        Numerical estimate of the test specificity\n",
        "    sensitivity_confidence_interval : Tuple (float, float)\n",
        "        Lower and upper bounds on the alpha confidence interval for sensitivity\n",
        "    specificity_confidence_interval\n",
        "        Lower and upper bounds on the alpha confidence interval for specificity\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    [1] R. G. Newcombe and D. G. Altman, Proportions and their differences, in Statisics\n",
        "    with Confidence: Confidence intervals and statisctical guidelines, 2nd Ed., D. G. Altman,\n",
        "    D. Machin, T. N. Bryant and M. J. Gardner (Eds.), pp. 45-57, BMJ Books, 2000.\n",
        "    [2] E. B. Wilson, Probable inference, the law of succession, and statistical inference,\n",
        "    J Am Stat Assoc 22:209-12, 1927.\n",
        "    \"\"\"\n",
        "\n",
        "    #\n",
        "    z = -ndtri((1.0-alpha)/2)\n",
        "\n",
        "    # Compute sensitivity using method described in [1]\n",
        "    sensitivity_point_estimate = TP/(TP + FN)\n",
        "    sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
        "\n",
        "    # Compute specificity using method described in [1]\n",
        "    #specificity_point_estimate = TN/(TN + FP)\n",
        "    #specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
        "\n",
        "    # Compute PPV using method described in [1]\n",
        "    ppv_point_estimate = TP/(TP + FP)\n",
        "    ppv_confidence_interval = _proportion_confidence_interval(TP, TP + FP, z)\n",
        "\n",
        "    return sensitivity_point_estimate, ppv_point_estimate, sensitivity_confidence_interval, ppv_confidence_interval\n",
        "\n",
        "for a in [0.95, 0.99]:\n",
        "    sensitivity_point_estimate, specificity_point_estimate, \\\n",
        "        sensitivity_confidence_interval, specificity_confidence_interval \\\n",
        "        = sensitivity_and_specificity_with_confidence_intervals(6502, 2924, 893, 21417, alpha=a)\n",
        "    print(\"Sensitivity: %f, Specificity: %f\" %(sensitivity_point_estimate, specificity_point_estimate))\n",
        "    print(\"alpha = %f CI for sensitivity:\"%a, sensitivity_confidence_interval)\n",
        "    print(\"alpha = %f CI for specificity:\"%a, specificity_confidence_interval)\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDQztqKdHrhY"
      },
      "outputs": [],
      "source": [
        "#For Reference\n",
        "\"\"\"\n",
        "for a in [0., 0.5, 0.9, 0.95, 0.99, 0.999999]:\n",
        "    sensitivity_point_estimate, specificity_point_estimate, \\\n",
        "        sensitivity_confidence_interval, specificity_confidence_interval \\\n",
        "        = sensitivity_and_specificity_with_confidence_intervals(6502, 1612, 893, 16807, alpha=a)\n",
        "    print(\"Sensitivity: %f, Specificity: %f\" %(sensitivity_point_estimate, specificity_point_estimate))\n",
        "    print(\"alpha = %f CI for sensitivity:\"%a, sensitivity_confidence_interval)\n",
        "    print(\"alpha = %f CI for specificity:\"%a, specificity_confidence_interval)\n",
        "    print(\"\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVRiQ2EbU70p"
      },
      "outputs": [],
      "source": [
        "import numpy as np # import libraries\n",
        "from statsmodels.stats import contingency_tables\n",
        "import pandas as pd\n",
        "from scipy.stats import binom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY0i0AxWUkeM"
      },
      "outputs": [],
      "source": [
        "contingency_tables.mcnemar(cm,exact=True).pvalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdvvi2p7Auk3"
      },
      "outputs": [],
      "source": [
        "def parse_image(file_name):\n",
        "  \"\"\"\n",
        "  This function downloads and standardizes input JPEG images for the\n",
        "    inception_v1 model. Its applies the following processing:\n",
        "    - Reads JPG file.\n",
        "    - Decodes JPG file into colored image.\n",
        "    - Converts data type to standard tf.float32.\n",
        "    - Resizes image to expected Inception V1 input dimension of\n",
        "      (224, 224, 3) with preserved aspect ratio. E.g. don't stretch image.\n",
        "    - Pad image to (224, 224, 3) shape with black pixels.\n",
        "  Args:\n",
        "    file_name(str): Direct URL path to the JPG image.\n",
        "  Returns:\n",
        "    image(Tensor): A Tensor of floats with shape (224, 224, 3).\n",
        "    label(str): A text label for display above the image.\n",
        "  \"\"\"\n",
        "  image = tf.io.read_file(file_name)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, (224, 224), preserve_aspect_ratio=True)\n",
        "  image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fKsaM5pA1fV"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/My Drive/CT/'\n",
        "\n",
        "img_path = os.path.join(input_path, 'train', 'covid','volume-covid19-A-0684-0022.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nCjgh8xIdUH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL6wLKPnA6FS"
      },
      "outputs": [],
      "source": [
        "img = {'volume-covid19-A-0684-0022':img_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3msVbJtrA-jv"
      },
      "outputs": [],
      "source": [
        "img_name_tensors = {name: parse_image(img_path) for (name, img_path) in img.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22ZBgOVhBC7s"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,14))\n",
        "for n, (name, img_tensors) in enumerate(img_name_tensors.items()):\n",
        "  ax = plt.subplot(3,3,n+1)\n",
        "  ax.imshow(img_tensors)\n",
        "  ax.set_title(name)\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NOw8cHRBI8C"
      },
      "outputs": [],
      "source": [
        "# stack images into a batch for processing.\n",
        "image_titles = tf.convert_to_tensor(list(img_name_tensors.keys()))\n",
        "image_batch = tf.convert_to_tensor(list(img_name_tensors.values()))\n",
        "image_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9l2t_lhBtUb"
      },
      "outputs": [],
      "source": [
        "def top_k_predictions_scores_labels(model, img, label_vocab, top_k=3):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    model(tf.keras.Model): Trained Keras model.\n",
        "    img(tf.Tensor): A 4D tensor of floats with the shape\n",
        "      (img_n, img_height, img_width, 3).\n",
        "    label_vocab(numpy.ndarray): An array of strings with shape (1001,).\n",
        "    top_k(int): Number of results to return.\n",
        "  Returns:\n",
        "    k_predictions_idx(tf.Tensor): A tf.Tensor [n_images, top_k] of tf.int32\n",
        "      prediction indicies.\n",
        "    k_predictions_proba(tf.Tensor): A tf.Tensor [n_images, top_k] of tf.float32\n",
        "      prediction probabilities..\n",
        "    k_predictions_label(tf.Tensor): A tf.Tensor [n_images, top_k] of tf.string\n",
        "      prediction labels.\n",
        "  \"\"\"\n",
        "  # These are logits (unnormalized scores).\n",
        "  predictions = model(img)\n",
        "  # Convert logits into probabilities.\n",
        "  predictions_proba = tf.nn.softmax(predictions, axis=-1)\n",
        "  #predictions_proba = tf.nn.sigmoid(predictions)\n",
        "  #print(predictions_proba)\n",
        "  # Filter top k prediction probabilities and indices.\n",
        "  k_predictions_proba, k_predictions_idx = tf.math.top_k(\n",
        "      input=predictions_proba, k=top_k)\n",
        "  # Lookup top k prediction labels in label_vocab array.\n",
        "  k_predictions_label = tf.convert_to_tensor(\n",
        "      label_vocab[k_predictions_idx.numpy()],\n",
        "      dtype=tf.string)\n",
        "\n",
        "  return k_predictions_idx, k_predictions_label, k_predictions_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIkwscxkB9sZ"
      },
      "outputs": [],
      "source": [
        "def plot_img_predictions(model, img, img_titles, label_vocab, top_k=3):\n",
        "  \"\"\"Plot images with top_k predictions.\n",
        "  Args:\n",
        "    model(tf.keras.Model): Trained Keras model.\n",
        "    img(Tensor): A 4D Tensor of floats with the shape\n",
        "      (img_n, img_height, img_width, 3).\n",
        "    img_titles(Tensor): A Tensor of strings with the shape\n",
        "      (img_n, img_height, img_width, 3).\n",
        "    label_vocab(numpy.ndarray): An array of strings with shape (1001,).\n",
        "    top_k(int): Number of results to return.\n",
        "  Returns:\n",
        "    fig(matplotlib.pyplot.figure): fig object to utilize for displaying, saving\n",
        "      plots.\n",
        "  \"\"\"\n",
        "  pred_idx, pred_label, pred_proba = \\\n",
        "  top_k_predictions_scores_labels(\n",
        "      model=model,\n",
        "      img=img,\n",
        "      label_vocab=label_vocab,\n",
        "      top_k=top_k)\n",
        "\n",
        "  img_arr = img.numpy()\n",
        "  title_arr = img_titles.numpy()\n",
        "  pred_idx_arr = pred_idx.numpy()\n",
        "  pred_label_arr = pred_label.numpy()\n",
        "  pred_proba_arr = pred_proba.numpy()\n",
        "\n",
        "  n_rows = img_arr.shape[0]\n",
        "  # Preserve image height by converting pixels to inches based on dpi.\n",
        "  size = n_rows * (224 // 48)\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=img_arr.shape[0], ncols=1, figsize=(size, size), squeeze=False)\n",
        "  for idx, image in enumerate(img_arr):\n",
        "    axs[idx, 0].imshow(image)\n",
        "    axs[idx, 0].set_title(title_arr[idx].decode('utf-8'), fontweight='bold')\n",
        "    axs[idx, 0].axis('off')\n",
        "    for k in range(top_k):\n",
        "      k_idx = pred_idx_arr[idx][k]\n",
        "      k_label = pred_label_arr[idx][k].decode('utf-8')\n",
        "      k_proba = pred_proba_arr[idx][k]\n",
        "      if k==0:\n",
        "        s = 'Prediction {:}: ({:}-{:}) Score: {:.1%}'.format(k+1, k_idx, k_label, k_proba)\n",
        "        axs[idx, 0].text(244 + size, 102+(k*40), s, fontsize=12, fontweight='bold')\n",
        "      else:\n",
        "        s = 'Prediction {:}: ({:}-{:}) Score: {:.1%}'.format(k+1, k_idx, k_label, k_proba)\n",
        "        axs[idx, 0].text(244 + size, 102+(k*20), s, fontsize=12)\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXXziFr-CoKO"
      },
      "outputs": [],
      "source": [
        "test_labels = np.array(test_generator.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnyOLZflqUVT"
      },
      "outputs": [],
      "source": [
        "test_labels[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CKHLDMxCLDm"
      },
      "outputs": [],
      "source": [
        "_ = plot_img_predictions(\n",
        "    model=model,\n",
        "    img=image_batch,\n",
        "    img_titles=image_titles,\n",
        "    label_vocab=test_labels[0],\n",
        "    top_k=3\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpshJ6O3BlOY"
      },
      "outputs": [],
      "source": [
        "# name_baseline_tensors. Set random seed for reproducibility of random baseline image and associated attributions.\n",
        "tf.random.set_seed(42)\n",
        "name_baseline_tensors = {\n",
        "    'Baseline Image: Black': tf.zeros(shape=(224,224,3)),\n",
        "    'Baseline Image: Random': tf.random.uniform(shape=(224,224,3), minval=0.0, maxval=1.0),\n",
        "    'Baseline Image: White': tf.ones(shape=(224,224,3)),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1Mcp7YDC0Ux"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for n, (name, baseline_tensor) in enumerate(name_baseline_tensors.items()):\n",
        "  ax = plt.subplot(1,3,n+1)\n",
        "  ax.imshow(baseline_tensor)\n",
        "  ax.set_title(name)\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZF0b0GuDFhV"
      },
      "outputs": [],
      "source": [
        "m_steps=20\n",
        "alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM9rmxfnDKd_"
      },
      "outputs": [],
      "source": [
        "def generate_path_inputs(baseline,\n",
        "                         input,\n",
        "                         alphas):\n",
        "  \"\"\"Generate m interpolated inputs between baseline and input features.\n",
        "  Args:\n",
        "    baseline(Tensor): A 3D image tensor of floats with the shape\n",
        "      (img_height, img_width, 3).\n",
        "    input(Tensor): A 3D image tensor of floats with the shape\n",
        "      (img_height, img_width, 3).\n",
        "    alphas(Tensor): A 1D tensor of uniformly spaced floats with the shape\n",
        "      (m_steps,).\n",
        "  Returns:\n",
        "    path_inputs(Tensor): A 4D tensor of floats with the shape\n",
        "      (m_steps, img_height, img_width, 3).\n",
        "  \"\"\"\n",
        "  # Expand dimensions for vectorized computation of interpolations.\n",
        "  alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
        "  baseline_x = tf.expand_dims(baseline, axis=0)\n",
        "  input_x = tf.expand_dims(input, axis=0)\n",
        "  delta = input_x - baseline_x\n",
        "  path_inputs = baseline_x +  alphas_x * delta\n",
        "\n",
        "  return path_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnXgfJB8DQ8B"
      },
      "outputs": [],
      "source": [
        "path_inputs = generate_path_inputs(\n",
        "    baseline=name_baseline_tensors['Baseline Image: Black'],\n",
        "    input=img_name_tensors['C19_603970_26'],\n",
        "    alphas=alphas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgWVwzgqDWOB"
      },
      "outputs": [],
      "source": [
        "path_inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewcgbRbFDc3U"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=5, squeeze=False, figsize=(24, 24))\n",
        "\n",
        "axs[0,0].set_title('Baseline \\n alpha: {:.2f}'.format(alphas[0]))\n",
        "axs[0,0].imshow(path_inputs[0])\n",
        "axs[0,0].axis('off')\n",
        "\n",
        "axs[0,1].set_title('=> Interpolated Image # 1 \\n alpha: {:.2f}'.format(alphas[1]))\n",
        "axs[0,1].imshow(path_inputs[1])\n",
        "axs[0,1].axis('off')\n",
        "\n",
        "axs[0,2].set_title('=> Interpolated Image # 2 \\n alpha: {:.2f}'.format(alphas[2]))\n",
        "axs[0,2].imshow(path_inputs[2])\n",
        "axs[0,2].axis('off')\n",
        "\n",
        "axs[0,3].set_title('... => Interpolated Image # 10 \\n alpha: {:.2f}'.format(alphas[10]))\n",
        "axs[0,3].imshow(path_inputs[10])\n",
        "axs[0,3].axis('off')\n",
        "\n",
        "axs[0,4].set_title('... => Input Image \\n alpha: {:.2f}'.format(alphas[-1]))\n",
        "axs[0,4].imshow(path_inputs[-1])\n",
        "axs[0,4].axis('off')\n",
        "\n",
        "plt.tight_layout();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5EpWoW2DiE4"
      },
      "outputs": [],
      "source": [
        "def compute_gradients(model, path_inputs, target_class_idx):\n",
        "  \"\"\"Compute gradients of model predicted probabilties with respect to inputs.\n",
        "  Args:\n",
        "    mode(tf.keras.Model): Trained Keras model.\n",
        "    path_inputs(Tensor): A 4D tensor of floats with the shape\n",
        "      (m_steps, img_height, img_width, 3).\n",
        "    target_class_idx(Tensor): A 0D tensor of an int corresponding to the correct\n",
        "      ImageNet target class index.\n",
        "  Returns:\n",
        "    gradients(Tensor): A 4D tensor of floats with the shape\n",
        "      (m_steps, img_height, img_width, 3).\n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(path_inputs)\n",
        "    predictions = model(path_inputs)\n",
        "    # Note: IG requires softmax probabilities; converting Inception V1 logits.\n",
        "    outputs = tf.nn.softmax(predictions, axis=-1)[:, target_class_idx]\n",
        "    #outputs = tf.nn.sigmoid(predictions)[:, target_class_idx]\n",
        "    print(outputs)\n",
        "\n",
        "  gradients = tape.gradient(outputs, path_inputs)\n",
        "\n",
        "  return gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j43mIj4FDq5V"
      },
      "outputs": [],
      "source": [
        "path_gradients = compute_gradients(\n",
        "    model=model,\n",
        "    path_inputs=path_inputs,\n",
        "    target_class_idx=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuKdWe2SDvjC"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=5, squeeze=False, figsize=(24, 24))\n",
        "for i in range(5):\n",
        "  axs[0,i].imshow(tf.cast(255 * path_gradients[i], tf.uint8), cmap=plt.cm.inferno)\n",
        "  axs[0,i].axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yn6YmzpD1RZ"
      },
      "outputs": [],
      "source": [
        "pred = model(path_inputs)\n",
        "pred_proba = tf.nn.softmax(pred, axis=-1)[:, 0]\n",
        "#pred_proba = tf.nn.sigmoid(pred)[:, 0]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "ax1.plot(alphas, pred_proba)\n",
        "ax1.set_title('Target class predicted probability over alpha')\n",
        "ax1.set_ylabel('model p(target class)')\n",
        "ax1.set_xlabel('alpha')\n",
        "ax1.set_ylim([0,1])\n",
        "\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "# Average across interpolation steps\n",
        "average_grads = tf.math.reduce_mean(path_gradients, axis=[1,2,3])\n",
        "# Normalize average gradients to 0 to 1 scale. E.g. (x - min(x))/(max(x)-min(x))\n",
        "average_grads_norm = (average_grads-tf.math.reduce_min(average_grads))/(tf.math.reduce_max(average_grads)-tf.reduce_min(average_grads))\n",
        "ax2.plot(alphas, average_grads_norm)\n",
        "ax2.set_title('Average pixel gradients (normalized) over alpha')\n",
        "ax2.set_ylabel('Average pixel gradients')\n",
        "ax2.set_xlabel('alpha')\n",
        "ax2.set_ylim([0,1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPYL1GN8EB4J"
      },
      "outputs": [],
      "source": [
        "def plot_riemann_sums(fn, start_val, end_val, m_steps=10):\n",
        "  \"\"\"\n",
        "  Plot Riemann Sum integral approximations for single variable functions.\n",
        "  Args:\n",
        "    fn(function): Any single variable function.\n",
        "    start_val(int): Minimum function value constraint.\n",
        "    end_val(int): Maximum function value constraint.\n",
        "    m_steps(int): Linear interpolation steps for approximation.\n",
        "  Returns:\n",
        "    fig(matplotlib.pyplot.figure): fig object to utilize for displaying, saving\n",
        "      plots.\n",
        "  \"\"\"\n",
        "  # fn plot args\n",
        "  x = tf.linspace(start_val, end_val, m_steps**2+1)\n",
        "  y = fn(x)\n",
        "\n",
        "  fig = plt.figure(figsize=(16,4))\n",
        "\n",
        "  # Left Riemann Sum\n",
        "  lr_ax = plt.subplot(1,4,1)\n",
        "  lr_ax.plot(x, y)\n",
        "  lr_x = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "  lr_point = lr_x[:-1]\n",
        "  lr_height = fn(lr_x[:-1])\n",
        "  lr_ax.plot(lr_point, lr_height, 'b.', markersize=10)\n",
        "  lr_ax.bar(lr_point, lr_height, width=(end_val-start_val)/m_steps, alpha=0.2, align='edge', edgecolor='b')\n",
        "  lr_ax.set_title('Left Riemann Sum \\n m_steps = {}'.format(m_steps))\n",
        "  lr_ax.set_xlabel('alpha')\n",
        "  # Right Riemann Sum\n",
        "  rr_ax = plt.subplot(1,4,2)\n",
        "  rr_ax.plot(x, y)\n",
        "  rr_x = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "  rr_point = rr_x[1:]\n",
        "  rr_height = fn(rr_x[1:])\n",
        "  rr_ax.plot(rr_point, rr_height, 'b.', markersize=10)\n",
        "  rr_ax.bar(rr_point, rr_height, width=-(end_val-start_val)/m_steps, alpha=0.2, align='edge', edgecolor='b')\n",
        "  rr_ax.set_title('Right Riemann Sum \\n m_steps = {}'.format(m_steps))\n",
        "  rr_ax.set_xlabel('alpha')\n",
        "  # Midpoint Riemann Sum\n",
        "  mr_ax = plt.subplot(1,4,3)\n",
        "  mr_ax.plot(x, y)\n",
        "  mr_x = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "  mr_point = (mr_x[:-1] + mr_x[1:])/2\n",
        "  mr_height = fn(mr_point)\n",
        "  mr_ax.plot(mr_point, mr_height, 'b.', markersize=10)\n",
        "  mr_ax.bar(mr_point, mr_height, width=(end_val-start_val)/m_steps, alpha=0.2, edgecolor='b')\n",
        "  mr_ax.set_title('Midpoint Riemann Sum \\n m_steps = {}'.format(m_steps))\n",
        "  mr_ax.set_xlabel('alpha')\n",
        "  # Trapezoidal Riemann Sum\n",
        "  tp_ax = plt.subplot(1,4,4)\n",
        "  tp_ax.plot(x, y)\n",
        "  tp_x = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "  tp_y = fn(tp_x)\n",
        "  for i in range(m_steps):\n",
        "    xs = [tp_x[i], tp_x[i], tp_x[i+1], tp_x[i+1]]\n",
        "    ys = [0, tp_y[i], tp_y[i+1], 0]\n",
        "    tp_ax.plot(tp_x,tp_y,'b.',markersize=10)\n",
        "    tp_ax.fill_between(xs, ys, color='C0', edgecolor='blue', alpha=0.2)\n",
        "  tp_ax.set_title('Trapezoidal Riemann Sum \\n m_steps = {}'.format(m_steps))\n",
        "  tp_ax.set_xlabel('alpha')\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_ahmLc2EHkd"
      },
      "outputs": [],
      "source": [
        "_ = plot_riemann_sums(lambda x: tf.math.sin(x*math.pi), 0.0, 1.0, m_steps=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgsnZVkGE8FJ"
      },
      "outputs": [],
      "source": [
        "_ = plot_riemann_sums(lambda x: tf.math.sin(x*math.pi), 0.0, 1.0, m_steps=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8YcxOnlFA5A"
      },
      "outputs": [],
      "source": [
        "def generate_alphas(m_steps=50,\n",
        "                    method='riemann_trapezoidal'):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    m_steps(Tensor): A 0D tensor of an int corresponding to the number of linear\n",
        "      interpolation steps for computing an approximate integral. Default is 50.\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "      following methods are implemented:\n",
        "      - riemann_trapezoidal(default)\n",
        "      - riemann_left\n",
        "      - riemann_midpoint\n",
        "      - riemann_right\n",
        "  Returns:\n",
        "    alphas(Tensor): A 1D tensor of uniformly spaced floats with the shape\n",
        "      (m_steps,).\n",
        "  \"\"\"\n",
        "  m_steps_float = tf.cast(m_steps, float) # cast to float for division operations.\n",
        "\n",
        "  if method == 'riemann_trapezoidal':\n",
        "    alphas = tf.linspace(0.0, 1.0, m_steps+1) # needed to make m_steps intervals.\n",
        "  elif method == 'riemann_left':\n",
        "    alphas = tf.linspace(0.0, 1.0 - (1.0 / m_steps_float), m_steps)\n",
        "  elif method == 'riemann_midpoint':\n",
        "    alphas = tf.linspace(1.0 / (2.0 * m_steps_float), 1.0 - 1.0 / (2.0 * m_steps_float), m_steps)\n",
        "  elif method == 'riemann_right':\n",
        "    alphas = tf.linspace(1.0 / m_steps_float, 1.0, m_steps)\n",
        "  else:\n",
        "    raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "  return alphas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pzunsljFWXv"
      },
      "outputs": [],
      "source": [
        "alphas = generate_alphas(m_steps=20, method='riemann_trapezoidal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBFTR5xUFbGB"
      },
      "outputs": [],
      "source": [
        "def integral_approximation(gradients,\n",
        "                           method='riemann_trapezoidal'):\n",
        "  \"\"\"Compute numerical approximation of integral from gradients.\n",
        "\n",
        "  Args:\n",
        "    gradients(Tensor): A 4D tensor of floats with the shape\n",
        "      (m_steps, img_height, img_width, 3).\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "      following methods are implemented:\n",
        "      - riemann_trapezoidal(default)\n",
        "      - riemann_left\n",
        "      - riemann_midpoint\n",
        "      - riemann_right\n",
        "  Returns:\n",
        "    integrated_gradients(Tensor): A 3D tensor of floats with the shape\n",
        "      (img_height, img_width, 3).\n",
        "  \"\"\"\n",
        "  if method == 'riemann_trapezoidal':\n",
        "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
        "  elif method == 'riemann_left':\n",
        "    grads = gradients\n",
        "  elif method == 'riemann_midpoint':\n",
        "    grads = gradients\n",
        "  elif method == 'riemann_right':\n",
        "    grads = gradients\n",
        "  else:\n",
        "    raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "  # Average integration approximation.\n",
        "  integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
        "\n",
        "\n",
        "  return integrated_gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5dluKIBFiMv"
      },
      "outputs": [],
      "source": [
        "ig = integral_approximation(\n",
        "    gradients=path_gradients,\n",
        "    method='riemann_trapezoidal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlL2pQGBFnku"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def integrated_gradients(model,\n",
        "                         baseline,\n",
        "                         input,\n",
        "                         target_class_idx,\n",
        "                         m_steps=50,\n",
        "                         method='riemann_trapezoidal',\n",
        "                         batch_size=32\n",
        "                        ):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    model(keras.Model): A trained model to generate predictions and inspect.\n",
        "    baseline(Tensor): A 3D image tensor with the shape\n",
        "      (image_height, image_width, 3) with the same shape as the input tensor.\n",
        "    input(Tensor): A 3D image tensor with the shape\n",
        "      (image_height, image_width, 3).\n",
        "    target_class_idx(Tensor): An integer that corresponds to the correct\n",
        "      ImageNet class index in the model's output predictions tensor. Default\n",
        "        value is 50 steps.\n",
        "    m_steps(Tensor): A 0D tensor of an integer corresponding to the number of\n",
        "      linear interpolation steps for computing an approximate integral.\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "      following methods are implemented:\n",
        "      - riemann_trapezoidal(default)\n",
        "      - riemann_left\n",
        "      - riemann_midpoint\n",
        "      - riemann_right\n",
        "    batch_size(Tensor): A 0D tensor of an integer corresponding to a batch\n",
        "      size for alpha to scale computation and prevent OOM errors. Note: needs to\n",
        "      be tf.int64 and shoud be < m_steps. Default value is 32.\n",
        "  Returns:\n",
        "    integrated_gradients(Tensor): A 3D tensor of floats with the same\n",
        "      shape as the input tensor (image_height, image_width, 3).\n",
        "  \"\"\"\n",
        "\n",
        "  # 1. Generate alphas.\n",
        "  alphas = generate_alphas(m_steps=m_steps,\n",
        "                           method=method)\n",
        "\n",
        "  # Initialize TensorArray outside loop to collect gradients. Note: this data structure\n",
        "  # is similar to a Python list but more performant and supports backpropogation.\n",
        "  # See https://www.tensorflow.org/api_docs/python/tf/TensorArray for additional details.\n",
        "  gradient_batches = tf.TensorArray(tf.float32, size=m_steps+1)\n",
        "\n",
        "  # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
        "  # Note: this implementation opted for lightweight tf.range iteration with @tf.function.\n",
        "  # Alternatively, you could also use tf.data, which adds performance overhead for the IG\n",
        "  # algorithm but provides more functionality for working with tensors and image data pipelines.\n",
        "  for alpha in tf.range(0, len(alphas), batch_size):\n",
        "    from_ = alpha\n",
        "    to = tf.minimum(from_ + batch_size, len(alphas))\n",
        "    alpha_batch = alphas[from_:to]\n",
        "\n",
        "    # 2. Generate interpolated inputs between baseline and input.\n",
        "    interpolated_path_input_batch = generate_path_inputs(baseline=baseline,\n",
        "                                                         input=input,\n",
        "                                                         alphas=alpha_batch)\n",
        "\n",
        "    # 3. Compute gradients between model outputs and interpolated inputs.\n",
        "    gradient_batch = compute_gradients(model=model,\n",
        "                                       path_inputs=interpolated_path_input_batch,\n",
        "                                       target_class_idx=target_class_idx)\n",
        "\n",
        "    # Write batch indices and gradients to TensorArray. Note: writing batch indices with\n",
        "    # scatter() allows for uneven batch sizes. Note: this operation is similar to a Python list extend().\n",
        "    # See https://www.tensorflow.org/api_docs/python/tf/TensorArray#scatter for additional details.\n",
        "    gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)\n",
        "\n",
        "  # Stack path gradients together row-wise into single tensor.\n",
        "  total_gradients = gradient_batches.stack()\n",
        "\n",
        "  # 4. Integral approximation through averaging gradients.\n",
        "  avg_gradients = integral_approximation(gradients=total_gradients,\n",
        "                                         method=method)\n",
        "\n",
        "  # 5. Scale integrated gradients with respect to input.\n",
        "  integrated_gradients = (input - baseline) * avg_gradients\n",
        "\n",
        "  return integrated_gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPMeguFKF2oo"
      },
      "outputs": [],
      "source": [
        "ig_attributions = integrated_gradients(model=model,\n",
        "                          baseline=name_baseline_tensors['Baseline Image: Black'],\n",
        "                          input=img_name_tensors['C19_603970_26'],\n",
        "                          target_class_idx=0,\n",
        "                          m_steps=55,\n",
        "                          method='riemann_trapezoidal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFeJjeQMHOaC"
      },
      "outputs": [],
      "source": [
        "def convergence_check(model, attributions, baseline, input, target_class_idx):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    model(keras.Model): A trained model to generate predictions and inspect.\n",
        "    baseline(Tensor): A 3D image tensor with the shape\n",
        "      (image_height, image_width, 3) with the same shape as the input tensor.\n",
        "    input(Tensor): A 3D image tensor with the shape\n",
        "      (image_height, image_width, 3).\n",
        "    target_class_idx(Tensor): An integer that corresponds to the correct\n",
        "      ImageNet class index in the model's output predictions tensor. Default\n",
        "        value is 50 steps.\n",
        "  Returns:\n",
        "    (none): Prints scores and convergence delta to sys.stdout.\n",
        "  \"\"\"\n",
        "  # Your model's prediction on the baseline tensor. Ideally, the baseline score\n",
        "  # should be close to zero.\n",
        "  baseline_prediction = model(tf.expand_dims(baseline, 0))\n",
        "  baseline_score = tf.nn.softmax(tf.squeeze(baseline_prediction))[target_class_idx]\n",
        "  #baseline_score = tf.nn.sigmoid(baseline_prediction)\n",
        "  # Your model's prediction and score on the input tensor.\n",
        "  input_prediction = model(tf.expand_dims(input, 0))\n",
        "  input_score = tf.nn.softmax(tf.squeeze(input_prediction))[target_class_idx]\n",
        "  #input_score = tf.nn.sigmoid(input_prediction)\n",
        "  # Sum of your IG prediction attributions.\n",
        "  ig_score = tf.math.reduce_sum(attributions)\n",
        "  delta = ig_score - (input_score - baseline_score)\n",
        "  try:\n",
        "    # Test your IG score is <= 5% of the input minus baseline score.\n",
        "    tf.debugging.assert_near(ig_score, (input_score - baseline_score), rtol=0.05)\n",
        "    tf.print('Approximation accuracy within 5%.', output_stream=sys.stdout)\n",
        "  except tf.errors.InvalidArgumentError:\n",
        "    tf.print('Increase or decrease m_steps to increase approximation accuracy.', output_stream=sys.stdout)\n",
        "\n",
        "  #tf.print('Baseline score: {:.3f}'.format(baseline_score))\n",
        "  tf.print(baseline_score)\n",
        "  #tf.print('Input score: {:.3f}'.format(input_score))\n",
        "  #tf.print('IG score: {:.3f}'.format(ig_score))\n",
        "  #tf.print('Convergence delta: {:.3f}'.format(delta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKCWw0kHHqXu"
      },
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zEsb_5xHiSG"
      },
      "outputs": [],
      "source": [
        "convergence_check(model=model,\n",
        "                  attributions=ig_attributions,\n",
        "                  baseline=name_baseline_tensors['Baseline Image: Black'],\n",
        "                  input=img_name_tensors['C19_603970_26'],\n",
        "                  target_class_idx=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ET-itiHzQn"
      },
      "outputs": [],
      "source": [
        "def plot_img_attributions(model,\n",
        "                          baseline,\n",
        "                          img,\n",
        "                          target_class_idx,\n",
        "                          m_steps=50,\n",
        "                          cmap=None,\n",
        "                          overlay_alpha=0.4):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    model(keras.Model): A trained model to generate predictions and inspect.\n",
        "    baseline(Tensor): A 3D image tensor with the shape\n",
        "      (image_height, image_width, 3) with the same shape as the input tensor.\n",
        "    img(Tensor): A 3D image tensor with the shape\n",
        "      (image_height, image_width, 3).\n",
        "    target_class_idx(Tensor): An integer that corresponds to the correct\n",
        "      ImageNet class index in the model's output predictions tensor. Default\n",
        "        value is 50 steps.\n",
        "    m_steps(Tensor): A 0D tensor of an integer corresponding to the number of\n",
        "      linear interpolation steps for computing an approximate integral.\n",
        "    cmap(matplotlib.cm): Defaults to None. Reference for colormap options -\n",
        "      https://matplotlib.org/3.2.1/tutorials/colors/colormaps.html. Interesting\n",
        "      options to try are None and high contrast 'inferno'.\n",
        "    overlay_alpha(float): A float between 0 and 1 that represents the intensity\n",
        "      of the original image overlay.\n",
        "  Returns:\n",
        "    fig(matplotlib.pyplot.figure): fig object to utilize for displaying, saving\n",
        "      plots.\n",
        "  \"\"\"\n",
        "  # Attributions\n",
        "  ig_attributions = integrated_gradients(model=model,\n",
        "                          baseline=baseline,\n",
        "                          input=img,\n",
        "                          target_class_idx=target_class_idx,\n",
        "                          m_steps=m_steps)\n",
        "\n",
        "  convergence_check(model, ig_attributions, baseline, img, target_class_idx)\n",
        "\n",
        "  # Per the original paper, take the absolute sum of the attributions across\n",
        "  # color channels for visualization. The attribution mask shape is a greyscale image\n",
        "  # with shape (224, 224).\n",
        "  attribution_mask = tf.reduce_sum(tf.math.abs(ig_attributions), axis=-1)\n",
        "\n",
        "  # Visualization\n",
        "  fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
        "\n",
        "  axs[0,0].set_title('Baseline Image')\n",
        "  axs[0,0].imshow(baseline)\n",
        "  axs[0,0].axis('off')\n",
        "\n",
        "  axs[0,1].set_title('Original Image')\n",
        "  axs[0,1].imshow(img)\n",
        "  axs[0,1].axis('off')\n",
        "\n",
        "  axs[1,0].set_title('IG Attribution Mask')\n",
        "  axs[1,0].imshow(attribution_mask, cmap=cmap)\n",
        "  axs[1,0].axis('off')\n",
        "\n",
        "  axs[1,1].set_title('Original + IG Attribution Mask Overlay')\n",
        "  axs[1,1].imshow(attribution_mask, cmap=cmap)\n",
        "  axs[1,1].imshow(img, alpha=overlay_alpha)\n",
        "  axs[1,1].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF8iF5rqH6dS"
      },
      "outputs": [],
      "source": [
        "_ = plot_img_attributions(model=model,\n",
        "                          img=img_name_tensors['C19_603970_26'],\n",
        "                          baseline=name_baseline_tensors['Baseline Image: Black'],\n",
        "                          target_class_idx=0,\n",
        "                          m_steps=20,\n",
        "                          cmap=plt.cm.inferno,\n",
        "                          overlay_alpha=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b70EMoYKqUoy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # cv2.imshow does not work on Google Colab notebooks, which is why we are using cv2_imshow instead\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu1bbMCrqarQ"
      },
      "outputs": [],
      "source": [
        "#model = InceptionV3(weights='imagenet')\n",
        "model = model_loaded\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nml4_fjFqniQ"
      },
      "outputs": [],
      "source": [
        "!wget https://indiasendangered.com/wp-content/uploads/2011/09/elephant.jpg\n",
        "!wget https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12234558/Chinook-On-White-03.jpg\n",
        "!wget https://icatcare.org/app/uploads/2018/07/Thinking-of-getting-a-cat.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pWfN2q55qs_t"
      },
      "outputs": [],
      "source": [
        "ORIGINAL = '/content/drive/My Drive/data_byclass_jan20/test/positive/MIDRC-RICORD-1C-SITE2-000265-99793-1.png'\n",
        "DIM = 224\n",
        "\n",
        "img = image.load_img(ORIGINAL, target_size=(DIM, DIM))\n",
        "\n",
        "cv2_imshow(cv2.imread(ORIGINAL)) # Visualize image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMFN4yJIqym4"
      },
      "outputs": [],
      "source": [
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "#print(decode_predictions(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vU_luuqwjRu"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(preds,axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EzfFCCuq8hd"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  last_conv_layer = model.get_layer('separable_conv2d_13')\n",
        "  iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "  model_out, last_conv_layer = iterate(x)\n",
        "  class_out = model_out[:, np.argmax(model_out[0])]\n",
        "  grads = tape.gradient(class_out, last_conv_layer)\n",
        "  pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1wKY6_TrNWK"
      },
      "outputs": [],
      "source": [
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = heatmap.reshape((7,7))\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_0Vcj6LrkjT"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(ORIGINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxs8bpO7rqdC"
      },
      "outputs": [],
      "source": [
        "INTENSITY = 0.5\n",
        "\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "img = heatmap * INTENSITY + img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wTpYUHC1rvj4"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(cv2.imread(ORIGINAL))\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFG-eoK3qHNW"
      },
      "outputs": [],
      "source": [
        "#GRAD-CAM\n",
        "def gradCAM(orig, intensity=0.5, res=250):\n",
        "  img = image.load_img(orig, target_size=(DIM, DIM))\n",
        "\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "\n",
        "  preds = model.predict(x)\n",
        "  print(decode_predictions(preds)[0][0][1]) # prints the class of image\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    last_conv_layer = model.get_layer('separable_conv2d_43')\n",
        "    iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "    model_out, last_conv_layer = iterate(x)\n",
        "    class_out = model_out[:, np.argmax(model_out[0])]\n",
        "    grads = tape.gradient(class_out, last_conv_layer)\n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "  heatmap /= np.max(heatmap)\n",
        "  heatmap = heatmap.reshape((8, 8))\n",
        "\n",
        "  img = cv2.imread(orig)\n",
        "\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "  heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "  img = heatmap * intensity + img\n",
        "\n",
        "  cv2_imshow(cv2.resize(cv2.imread(orig), (res, res)))\n",
        "  cv2_imshow(cv2.resize(img, (res, res)))\n",
        "\n",
        "gradCAM(\"Chinook-On-White-03.jpg\")\n",
        "gradCAM(\"Thinking-of-getting-a-cat.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQWFxnFSsHHF"
      },
      "outputs": [],
      "source": [
        "pip install numpy==1.19.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPP7x1-dseaf"
      },
      "outputs": [],
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG1zSwd97xs7FOdX1IzNpH"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}